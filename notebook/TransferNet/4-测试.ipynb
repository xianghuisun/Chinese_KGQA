{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9439bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math,json\n",
    "from transformers import AutoModel\n",
    "import os,re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import transformers\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "from IPython import embed\n",
    "bert_name='/home/xhsun/Desktop/huggingfaceModels/chinese-roberta-wwm/'\n",
    "tokenizer=AutoTokenizer.from_pretrained(bert_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da58a6f5",
   "metadata": {},
   "source": [
    "# 获取实体、关系、三元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a2c968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 191000/191000 [00:00<00:00, 1853139.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3906/3906 [00:00<00:00, 1996703.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 369812/369812 [00:00<00:00, 920876.40it/s]\n"
     ]
    }
   ],
   "source": [
    "kg_folder='/home/xhsun/Desktop/KG/nlpcc2018/knowledge/small_knowledge/'\n",
    "\n",
    "ent2id = {}\n",
    "with open(os.path.join(kg_folder, 'entities.dict')) as f:\n",
    "    lines=f.readlines()\n",
    "for i in tqdm(range(len(lines))):\n",
    "    l = lines[i].strip().split('\\t')\n",
    "    ent2id[l[0].strip()] = len(ent2id)\n",
    "id2ent={k:v for v,k in ent2id.items()}\n",
    "\n",
    "rel2id = {}\n",
    "with open(os.path.join(kg_folder, 'relations.dict')) as f:\n",
    "    lines=f.readlines()\n",
    "for i in tqdm(range(len(lines))):\n",
    "    l = lines[i].strip().split('\\t')\n",
    "    rel2id[l[0].strip()] = int(l[1])\n",
    "\n",
    "triples = []\n",
    "bad_count=0\n",
    "with open(os.path.join(kg_folder, 'small_kb')) as f:\n",
    "    lines=f.readlines()\n",
    "for i in tqdm(range(len(lines))):\n",
    "    l = lines[i].strip().split('|||')\n",
    "    try:\n",
    "        s = ent2id[l[0].strip()]\n",
    "        p = rel2id[l[1].strip()]\n",
    "        o = ent2id[l[2].strip()]\n",
    "        triples.append((s, p, o))\n",
    "    except:\n",
    "        bad_count+=1\n",
    "triples = torch.LongTensor(triples)\n",
    "\n",
    "Tsize = len(triples)\n",
    "Esize = len(ent2id)\n",
    "num_relations = len(rel2id)\n",
    "\n",
    "idx = torch.LongTensor([i for i in range(Tsize)])\n",
    "Msubj = torch.sparse.FloatTensor(\n",
    "    torch.stack((idx, triples[:,0])), torch.FloatTensor([1] * Tsize), torch.Size([Tsize, Esize]))\n",
    "Mobj = torch.sparse.FloatTensor(\n",
    "    torch.stack((idx, triples[:,2])), torch.FloatTensor([1] * Tsize), torch.Size([Tsize, Esize]))\n",
    "Mrel = torch.sparse.FloatTensor(\n",
    "    torch.stack((idx, triples[:,1])), torch.FloatTensor([1] * Tsize), torch.Size([Tsize, num_relations]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a07b81",
   "metadata": {},
   "source": [
    "# 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d991b338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/xhsun/Desktop/huggingfaceModels/chinese-roberta-wwm/ were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "class TransferNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.num_steps = 2\n",
    "        \n",
    "        self.bert_encoder = AutoModel.from_pretrained(bert_name, return_dict=True)\n",
    "        dim_hidden = self.bert_encoder.config.hidden_size\n",
    "\n",
    "        self.step_encoders = []\n",
    "        for i in range(self.num_steps):\n",
    "            m = nn.Sequential(\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "            self.step_encoders.append(m)\n",
    "            self.add_module('step_encoders_{}'.format(i), m)\n",
    "\n",
    "        self.rel_classifier = nn.Linear(dim_hidden, num_relations)\n",
    "        self.hop_selector = nn.Linear(dim_hidden, self.num_steps)\n",
    "\n",
    "\n",
    "    def follow(self, e, r):\n",
    "        x = torch.sparse.mm(Msubj, e.t()) * torch.sparse.mm(Mrel, r.t())\n",
    "        return torch.sparse.mm(Mobj.t(), x).t() # [bsz, Esize]\n",
    "\n",
    "    def forward(self, heads, questions, answers=None, entity_range=None):\n",
    "        q = self.bert_encoder(**questions)\n",
    "        q_embeddings, q_word_h = q.pooler_output, q.last_hidden_state # (bsz, dim_h), (bsz, len, dim_h)\n",
    "\n",
    "        device = heads.device\n",
    "        last_e = heads\n",
    "        word_attns = []\n",
    "        rel_probs = []\n",
    "        ent_probs = []\n",
    "        for t in range(self.num_steps):\n",
    "            cq_t = self.step_encoders[t](q_embeddings) # [bsz, dim_h]\n",
    "            q_logits = torch.sum(cq_t.unsqueeze(1) * q_word_h, dim=2) # [bsz, max_q]\n",
    "            q_dist = torch.softmax(q_logits, 1) # [bsz, max_q]\n",
    "            q_dist = q_dist * questions['attention_mask'].float()\n",
    "            q_dist = q_dist / (torch.sum(q_dist, dim=1, keepdim=True) + 1e-6) # [bsz, max_q]\n",
    "            word_attns.append(q_dist)\n",
    "            ctx_h = (q_dist.unsqueeze(1) @ q_word_h).squeeze(1) # [bsz, dim_h]\n",
    "\n",
    "            rel_logit = self.rel_classifier(ctx_h) # [bsz, num_relations]\n",
    "            # rel_dist = torch.softmax(rel_logit, 1) # bad\n",
    "            rel_dist = torch.sigmoid(rel_logit)\n",
    "            rel_probs.append(rel_dist)\n",
    "\n",
    "            # sub, rel, obj = self.triples[:,0], self.triples[:,1], self.triples[:,2]\n",
    "            # sub_p = last_e[:, sub] # [bsz, #tri]\n",
    "            # rel_p = rel_dist[:, rel] # [bsz, #tri]\n",
    "            # obj_p = sub_p * rel_p\n",
    "            # last_e = torch.index_add(torch.zeros_like(last_e), 1, obj, obj_p)\n",
    "            last_e = self.follow(last_e, rel_dist) # faster than index_add\n",
    "\n",
    "            # reshape >1 scores to 1 in a differentiable way\n",
    "            m = last_e.gt(1).float()\n",
    "            z = (m * last_e + (1-m)).detach()\n",
    "            last_e = last_e / z\n",
    "\n",
    "            ent_probs.append(last_e)\n",
    "\n",
    "        hop_res = torch.stack(ent_probs, dim=1) # [bsz, num_hop, num_ent]\n",
    "        hop_attn = torch.softmax(self.hop_selector(q_embeddings), dim=1).unsqueeze(2) # [bsz, num_hop, 1]\n",
    "        last_e = torch.sum(hop_res * hop_attn, dim=1) # [bsz, num_ent]\n",
    "\n",
    "        if not self.training:\n",
    "            return {\n",
    "                'e_score': last_e,\n",
    "                'word_attns': word_attns,\n",
    "                'rel_probs': rel_probs,\n",
    "                'ent_probs': ent_probs,\n",
    "                'hop_attn': hop_attn.squeeze(2)\n",
    "            }\n",
    "        else:\n",
    "            weight = answers * 99 + 1\n",
    "            loss = torch.sum(entity_range * weight * torch.pow(last_e - answers, 2)) / torch.sum(entity_range * weight)\n",
    "\n",
    "            return {'loss': loss}\n",
    "\n",
    "model = TransferNet()\n",
    "model.load_state_dict(torch.load('/home/xhsun/Desktop/code/KG/TransferNet-master/save_dir/model.pt',map_location='cpu'))\n",
    "model=model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf6b49",
   "metadata": {},
   "source": [
    "# 加载测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08885bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tokens_to_ids(topic_entity,question,answer=None):\n",
    "    question=question.replace('<'+topic_entity+'>','NE')\n",
    "    #print(question)\n",
    "    head=[ent2id[topic_entity]]\n",
    "    token_ids=tokenizer(question.strip(), max_length=64, padding='max_length', return_tensors=\"pt\")\n",
    "    if answer==None:\n",
    "        return head,token_ids\n",
    "    else:\n",
    "        ans_ids=[ent2id[answer]]\n",
    "        return head,token_ids,ans_ids\n",
    "    \n",
    "def toOneHot(indices):\n",
    "    indices = torch.LongTensor(indices)\n",
    "    vec_len = len(ent2id)\n",
    "    one_hot = torch.FloatTensor(vec_len)\n",
    "    one_hot.zero_()\n",
    "    one_hot.scatter_(0, indices, 1)\n",
    "    return one_hot\n",
    "\n",
    "all_examples=[]\n",
    "with open(\"/home/xhsun/Desktop/KG/nlpcc2018/knowledge/small_knowledge/test.txt\") as f:\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        all_examples.append(line.strip().split('\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980079bf",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcb044a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:52<00:00, 11.57it/s]\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "all_predict_examples=[]\n",
    "for i in tqdm(range(len(all_examples))):\n",
    "    example=all_examples[i]\n",
    "    question,answer=example\n",
    "    topic_entity=re.findall(pattern='<(.*)>',string=question)[0]\n",
    "    head,token_ids=convert_tokens_to_ids(topic_entity,question,answer=None)\n",
    "    #print(head,token_ids,ans_ids)\n",
    "    one_hot_head=toOneHot(head)\n",
    "    with torch.no_grad():\n",
    "        result=model(*(one_hot_head.unsqueeze(0),token_ids))\n",
    "    e_score=result['e_score']\n",
    "    scores,idx=torch.max(e_score,dim=1)\n",
    "    score=scores.tolist()[0]\n",
    "    predict_id=idx.tolist()[0]\n",
    "    predict_answer=id2ent[predict_id]\n",
    "    all_predict_examples.append({'score':score,'idx':idx,'predict_answer':predict_answer})\n",
    "        \n",
    "    if predict_answer==answer:\n",
    "        correct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96456ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.738"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/len(all_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f012639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"《碧血剑》的导演\"\n",
    "topic_entity='《碧血剑》'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02dcad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "head,token_ids=convert_tokens_to_ids(topic_entity,question,answer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e32c63d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_head=toOneHot(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53362fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    result=model(*(one_hot_head.unsqueeze(0),token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ad91b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_score=result['e_score']\n",
    "scores,idx=torch.max(e_score,dim=1)\n",
    "score=scores.tolist()[0]\n",
    "predict_id=idx.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22dbc497",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_answer=id2ent[predict_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bfc5f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'张纪中'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e3dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
