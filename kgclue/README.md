# [KgCLUE](https://github.com/CLUEbenchmark/KgCLUE)，大规模中文开源知识图谱问答项目



- notebook文件夹主要记录处理数据和图谱相关的代码
- NERPlusRE文件夹下采用的模型是NER+RE(Relation Extraction)的策略
- TransferNet文件夹下采用的模型是EMNLP2021年的一篇论文[TransferNet](https://github.com/shijx12/TransferNet)



**实验主要从两个角度记录：**

1. 实体识别和关系抽取（从这个角度出发，相关的研究内容包括：实体消歧、联合建模、召回排序等。**这种策略涉及诸多模块，偏向于工业界**）
2. KGQA（这个角度主要**偏向于学术界**的论文，这种策略下要求问题中给出主题实体，而且关系和实体数量不能太多。目前学术界的KGQA主要集中研究多跳问答）



# KGQA



利用KGQA的模型进行实验前，需要一定的数据处理步骤：

- KGQA的策略需要问题中给出主题实体，而问答数据中没有标出主题实体，所以需要先做出一个实体识别模型，让该模型预测出测试集中每一个问题中的主题实体。
- **实验表明，KGQA的策略下，直接将整个KG用来训练对内存、显存容量要求高，尤其是时间的问题，推理一次需要7分钟，训练时间更是无法估计，最主要的是会影响准确率**。因此需要缩小知识图谱。
- 缩小知识图谱的方式主要包括：（1）仅保留问答对中涉及的关系。这句话的意思是：根据问答数据集中的(q,a)对，其中q给出了主题实体。我们将主题实体看作头实体head，答案看作尾实体tail，这样就得到了(head,tail)下所有可能的关系（一对头实体和尾实体之间大部分情况下只有一个关系）。得到这样的关系集合后，对于知识图谱中的每一个三元组，如果这个三元组的关系不在这个关系集合中，就可以去除这个三元组。（2）仅保留N-hop路径内的实体。这句话的意思是：根据问答数据集中的每一个问题中的主题实体，仅保留与这个实体相连的在N-hop路径内的实体，超出N-hop外的实体就不要了。N一般设置为2-3即可。因为一般的问题最多也就2到3跳。目前KgCLUE的问题还都是单挑问答



数据处理的流程是：

```python
sub_map=defaultdict(list)
so_map=defaultdict(list)

for s,p,o in all_triplets:
    sub_map[s].append((p,o))
    so_map[(s,o)].append(p)
#sub_map记录的是每一个头实体与其直接相连的所有可能的路径
#so_map记录的是每一个(头实体，尾实体)可能出现的所有关系
small_relations=set()
for topic_entity,answer in qa_pairs:
    for p in so_map[(topic_entity,answer)]:
        small_relations.add(p)
#small_relations记录的就是问答数据集中每一个问题涉及的关系

small_triples=set()
for topic_entity,answer in qa_pairs:
    for p,o in sub_map[topic_entity]:
        if p in small_relations:
            #如果关系在预先统计的关系集合中
            small_triples.add((topic_entity,p,o))
#small_triples就会是一个非常小的知识图谱，因为它仅包含了问答数据中涉及的关系和三元组
```





| 知识图谱                | 三元组   | 实体    | 关系   | acc(TransferNet模型) |
| ----------------------- | -------- | ------- | ------ | -------------------- |
| 原始                    | 22884223 | 9418365 | 245838 | -                    |
| 过滤掉关系为''的case    | 22883549 | 9418104 | 245837 | -                    |
| 2-hop内                 | 344427   | 230199  | 19889  | 0.266                |
| 1-hop内                 | 222385   | 170461  | 15179  | 0.267                |
| 1-hop内且仅保留部分关系 | 189599   | 146724  | 4524   | 0.689                |

- 过滤掉关系为''的case。指的是：原来的Knowledge.txt中存在关系是空字符串''的情况

- 2-hop内。指的是：取提交测试集和问答数据集中的所有2-hop内的实体

- 1-hop内。指的是：取提交测试集和问答数据集中的所有1-hop内的实体
- 1-hop内且仅保留部分关系。指的是：取提交测试集和问答数据集中的所有1-hop内的实体，而且仅保留问答数据集中涉及的关系。（这种策略有问题，因为存在着head,tail，但是没有对应的relation的情况）



<font color=red size= 5>所以要么就是仅保留N-hop路径内出现的所有实体和关系。要么就是预先统计问答数据集中涉及到的所有关系集合，然后针对每一个问题中的主题实体，仅仅保留与该主题实体相连，且关系在统计的关系集合中的三元组</font>



**利用1-hop内且仅保留部分关系这个模型，也就是0.689这个模型，排行版的分数如下：**

Score=(EM-O+F1-O)*0.5

| Model                | Score  | EM-S   | EM-P | EM-O   | EM-ALL | F1-S   | F1-P   | F1-O   | F1-ALL |
| -------------------- | ------ | ------ | ---- | ------ | ------ | ------ | ------ | ------ | ------ |
| TransferNet+version1 | 37.999 | 74.600 | 0.1  | 35.633 | 0.067  | 84.243 | 23.733 | 40.366 | 54.921 |

- TransferNet+version1 即1-hop内且仅保留部分关系。包括QA数据集中每一个(q,a)的关系集合，以及预测的测试集中每一个head实体的sub_map中的关系集合，最终有4524个关系。74.6是实体识别模型预测topic实体的准确率。



学术界的KGQA模型。如TransferNet、EmbedKGQA，这些模型的整体策略都是根据问题中的topic实体，以及问题的语义表示向量，实现多跳问答。不是很注重关系的分类（原因应该是多跳问答的情况下关系无法分类）





# 实体识别+关系抽取

| Model          | Score  | EM-S   | EM-P   | EM-O   | EM-ALL | F1-S   | F1-P   | F1-O   | F1-ALL |
| -------------- | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |
| NER+RE（串行） | 57.951 | 74.600 | 56.667 | 56.633 | 54.800 | 84.243 | 71.648 | 59.269 | 72.737 |
|                |        |        |        |        |        |        |        |        |        |

- NER+RE（串行）指的是先进行实体识别，再进行关系提取。

