# [KgCLUE](https://github.com/CLUEbenchmark/KgCLUE)，大规模中文开源知识图谱问答项目



- notebook文件夹主要记录处理数据和图谱相关的代码
- NERPlusRE文件夹下采用的模型是NER+RE(Relation Extraction)的策略
- TransferNet文件夹下采用的模型是EMNLP2021年的一篇论文[TransferNet](https://github.com/shijx12/TransferNet)



**实验主要从两个角度记录：**

1. 实体识别和关系抽取（从这个角度出发，相关的研究内容包括：实体消歧、联合建模、召回排序等。**这种策略涉及诸多模块，偏向于工业界**）
2. KGQA（这个角度主要**偏向于学术界**的论文，这种策略下要求问题中给出主题实体，而且关系和实体数量不能太多。目前学术界的KGQA主要集中研究多跳问答）



# KGQA



利用KGQA的模型进行实验前，需要一定的数据处理步骤：

- KGQA的策略需要问题中给出主题实体，而问答数据中没有标出主题实体，所以需要先做出一个实体识别模型，让该模型预测出测试集中每一个问题中的主题实体。
- **实验表明，KGQA的策略下，直接将整个KG用来训练对内存、显存容量要求高，尤其是时间的问题，推理一次需要7分钟，训练时间更是无法估计，最主要的是会影响准确率**。因此需要缩小知识图谱。
- 缩小知识图谱的方式主要包括：（1）仅保留问答对中涉及的关系。这句话的意思是：根据问答数据集中的(q,a)对，其中q给出了主题实体。我们将主题实体看作头实体head，答案看作尾实体tail，这样就得到了(head,tail)下所有可能的关系（一对头实体和尾实体之间大部分情况下只有一个关系）。得到这样的关系集合后，对于知识图谱中的每一个三元组，如果这个三元组的关系不在这个关系集合中，就可以去除这个三元组。（2）仅保留N-hop路径内的实体。这句话的意思是：根据问答数据集中的每一个问题中的主题实体，仅保留与这个实体相连的在N-hop路径内的实体，超出N-hop外的实体就不要了。N一般设置为2-3即可。因为一般的问题最多也就2到3跳。目前KgCLUE的问题还都是单挑问答



数据处理的流程是：

```python
sub_map=defaultdict(list)
so_map=defaultdict(list)

for s,p,o in all_triplets:
    sub_map[s].append((p,o))
    so_map[(s,o)].append(p)
#sub_map记录的是每一个头实体与其直接相连的所有可能的路径
#so_map记录的是每一个(头实体，尾实体)可能出现的所有关系
small_relations=set()
for topic_entity,answer in qa_pairs:
    for p in so_map[(topic_entity,answer)]:
        small_relations.add(p)
#small_relations记录的就是问答数据集中每一个问题涉及的关系

small_triples=set()
for topic_entity,answer in qa_pairs:
    for p,o in sub_map[topic_entity]:
        if p in small_relations:
            #如果关系在预先统计的关系集合中
            small_triples.add((topic_entity,p,o))
#small_triples就会是一个非常小的知识图谱，因为它仅包含了问答数据中涉及的关系和三元组
```





| 知识图谱                | 三元组   | 实体    | 关系   | acc(TransferNet模型) |
| ----------------------- | -------- | ------- | ------ | -------------------- |
| 原始                    | 22884223 | 9418365 | 245838 | -                    |
| 过滤掉关系为''的case    | 22883549 | 9418104 | 245837 | -                    |
| 2-hop内                 | 344427   | 230199  | 19889  | 0.266                |
| 1-hop内                 | 222385   | 170461  | 15179  | 0.267                |
| 1-hop内且仅保留部分关系 | 189599   | 146724  | 4524   | 0.689                |

- 过滤掉关系为''的case。指的是：原来的Knowledge.txt中存在关系是空字符串''的情况

- 2-hop内。指的是：取提交测试集和问答数据集中的所有2-hop内的实体

- 1-hop内。指的是：取提交测试集和问答数据集中的所有1-hop内的实体
- 1-hop内且仅保留部分关系。指的是：取提交测试集和问答数据集中的所有1-hop内的实体，而且仅保留问答数据集中涉及的关系。（这种策略有问题，因为存在着head,tail，但是没有对应的relation的情况）



<font color=red size= 5>所以要么就是仅保留N-hop路径内出现的所有实体和关系。要么就是预先统计问答数据集中涉及到的所有关系集合，然后针对每一个问题中的主题实体，仅仅保留与该主题实体相连，且关系在统计的关系集合中的三元组</font>



**利用1-hop内且仅保留部分关系这个模型，也就是0.689这个模型，排行版的分数如下：**

Score=(EM-O+F1-O)*0.5

| Model                | Score  | EM-S   | EM-P | EM-O   | EM-ALL | F1-S   | F1-P   | F1-O   | F1-ALL |
| -------------------- | ------ | ------ | ---- | ------ | ------ | ------ | ------ | ------ | ------ |
| TransferNet+version1 | 37.999 | 74.600 | 0.1  | 35.633 | 0.067  | 84.243 | 23.733 | 40.366 | 54.921 |

- TransferNet+version1 即1-hop内且仅保留部分关系。包括QA数据集中每一个(q,a)的关系集合，以及预测的测试集中每一个head实体的sub_map中的关系集合，最终有4524个关系。74.6是实体识别模型预测topic实体的准确率。



学术界的KGQA模型。如TransferNet、EmbedKGQA，这些模型的整体策略都是根据问题中的topic实体，以及问题的语义表示向量，实现多跳问答。不是很注重关系的分类（原因应该是多跳问答的情况下关系无法分类）





# 实体识别+关系抽取

不管是串行还是联合建模，在大规模的知识图谱场景下，关系数量是非常多的，因此将其视为分类任务未必是好的策略。

下表的模型是在缩小了关系数量之后train出来的模型，缩小关系的规则是仅保留问答数据中涉及的关系以及问题的主题实体内的一跳路径上的关系。其余超出一跳路径外的关系以及非问答数据集中问题的主题实体外的关系均不考虑。最终得到的关系数量是4524。模型提交的分数如NER+RE(串行)

| Model          | Score  | EM-S   | EM-P   | EM-O   | EM-ALL | F1-S   | F1-P   | F1-O   | F1-ALL |
| -------------- | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |
| NER+RE（串行） | 57.951 | 74.600 | 56.667 | 56.633 | 54.800 | 84.243 | 71.648 | 59.269 | 72.737 |
|                |        |        |        |        |        |        |        |        |        |

- NER+RE（串行）指的是先进行实体识别，再进行关系提取。



另外的做法是：

1. 实体识别模型的训练
2. 构建别名映射字典，即key是实体，value是这个实体在KG中所有的别名（比如：[别名、中文名，英文名，原名，别称，昵称，简称，全称，中文名称，英文名称]，而且KG中凡是有歧义的实体，大多以括号形式给出详细信息，如红楼梦（四大名著），那么红楼梦（四大名著）就可以视为红楼梦的别名实体）。**这是最简单的实体消歧方法。**
3. 构造sub_map，sub指的是subject，也就是每一个实体作为头实体的情况下对应的所有可能的关系与尾实体。
4. 构造(问句，关系)对的集合作为训练集，训练一个用于文本匹配的模型，即预测哪一个关系和问句最相关。这一步也就是关系排序。（关系通常只是一个单词，蕴含的语义信息量太小，因此用Bi-Encoders这种策略效果可能不会太好。）
5. 测试阶段：
   1. 首先实体识别，找出头实体。
   2. 从别名映射字典中找出该头实体所有可能的别名实体，再根据sub_map找出每一个别名实体对应的所有的关系
   3. 将所有的候选关系与问句输入到文本匹配模型中计算每一个关系的分数，取得分最高的关系。
   4. 查找所有可能的别名实体中哪一个别名实体包含这个关系，这样就得到了对应的尾实体。将最终的尾实体集合（可能不止一个）作为答案返回。
